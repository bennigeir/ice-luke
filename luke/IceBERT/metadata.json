{
    "max_entity_length": 128,
    "max_mention_length": 30,
    "max_seq_length": 512,
	"model_config": {
		"_name_or_path": "pdfp",
		"architectures": [
			"RobertaForMaskedLM"
		],
		"attention_probs_dropout_prob": 0.1,
		"bert_model_name": "mideind/IceBERT-igc",
		"entity_emb_size": 768,
        "entity_vocab_size": 59943,
		"bos_token_id": 0,
		"eos_token_id": 2,
		"gradient_checkpointing": false,
		"hidden_act": "gelu",
		"hidden_dropout_prob": 0.1,
		"hidden_size": 768,
		"initializer_range": 0.02,
		"intermediate_size": 3072,
		"layer_norm_eps": 1e-05,
		"max_position_embeddings": 514,
		"model_type": "roberta",
		"num_attention_heads": 12,
		"num_hidden_layers": 12,
		"pad_token_id": 1,
		"type_vocab_size": 1,
		"vocab_size": 50000
	}
}